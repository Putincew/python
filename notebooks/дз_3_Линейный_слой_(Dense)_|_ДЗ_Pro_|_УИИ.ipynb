{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Putincew/python/blob/master/notebooks/%D0%B4%D0%B7_3_%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%B9_%D1%81%D0%BB%D0%BE%D0%B9_(Dense)_%7C_%D0%94%D0%97_Pro_%7C_%D0%A3%D0%98%D0%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_qXycKuUA51"
      },
      "source": [
        "### Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUMmCXubUHEb"
      },
      "source": [
        "Самостоятельно напишите нейронную сеть, которая может стать составной частью системы бота для игры в \"Крестики-нолики\". Используя подготовленную базу изображений, создайте и обучите нейронную сеть, распознающую две категории изображений: крестики и нолики. Добейтесь точности распознавания более 95% (accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvOL2h3EdC9y"
      },
      "source": [
        "# Подключение класса для создания нейронной сети прямого распространения\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Подключение класса для создания полносвязного слоя\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Подключение оптимизатора\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Подключение утилит для to_categorical\n",
        "from tensorflow.keras import utils\n",
        "# Подключение библиотеки для загрузки изображений\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# Подключение библиотеки для работы с массивами\n",
        "import numpy as np\n",
        "# Подключение модуля для работы с файлами\n",
        "import os\n",
        "# Подключение библиотек для отрисовки изображений\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Вывод изображения в ноутбуке, а не в консоли или файле\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lJSH41rM12IE",
        "outputId": "4d396d3c-10e5-4e21-8f3f-c249bcbeed37"
      },
      "source": [
        "# Загрузка датасета из облака\n",
        "import gdown\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_pro.zip', None, quiet=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hw_pro.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HAhCsCJ1_hJ"
      },
      "source": [
        "# Распаковываем архив hw_light.zip в папку hw_light\n",
        "!unzip -q hw_pro.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhHbCet01zmG",
        "outputId": "d9f2f3c0-4c2e-4937-e9a0-7bca1b180ee6"
      },
      "source": [
        "# Путь к директории с базой\n",
        "base_dir = '/content/hw_pro'\n",
        "# Создание пустого списка для загрузки изображений обучающей выборки\n",
        "x_train = []\n",
        "# Создание списка для меток классов\n",
        "y_train = []\n",
        "# Задание высоты и ширины загружаемых изображений\n",
        "img_height = 20\n",
        "img_width = 20\n",
        "# Перебор папок в директории базы\n",
        "for patch in os.listdir(base_dir):\n",
        "    # Перебор файлов в папках\n",
        "    for img in os.listdir(base_dir + '/' + patch):\n",
        "        # Добавление в список изображений текущей картинки\n",
        "        x_train.append(image.img_to_array(image.load_img(base_dir + '/' + patch + '/' + img,\n",
        "                                                         target_size=(img_height, img_width),\n",
        "                                                         color_mode='grayscale')))\n",
        "        # Добавление в массив меток, соответствующих классам\n",
        "        if patch == '0':\n",
        "            y_train.append(0)\n",
        "        else:\n",
        "            y_train.append(1)\n",
        "# Преобразование в numpy-массив загруженных изображений и меток классов\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "# Вывод размерностей\n",
        "print('Размер массива x_train', x_train.shape)\n",
        "print('Размер массива y_train', y_train.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер массива x_train (102, 20, 20, 1)\n",
            "Размер массива y_train (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJLh3F3N2DCD"
      },
      "source": [
        "x_tr, x_test, y_tr, y_test = train_test_split(x_train, y_train, test_size = 0.1, random_state = 43)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_test[0-1])\n",
        "model = Sequential()\n",
        "model.add(Dense(300, input_dim = 400, activation = \"relu\"))\n",
        "# model.add(Dense(100, input_dim = 300, activation = \"relu\"))\n",
        "model.add(Dense(1, input_dim = 100, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(x_tr, y_tr, batch_size = 128, epochs = 15, verbose = 1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQcRfwN_hjPs",
        "outputId": "5f31e225-b6a8-48c9-bc8a-00e802c74dc0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[254. 255. 254. 255. 254. 253. 255. 255. 253. 255. 255. 254. 255. 254.\n",
            " 255. 252. 255. 254. 255. 253. 254. 255. 255. 251. 255. 255. 252. 255.\n",
            " 255. 253. 253. 255. 253. 254. 250. 255. 253. 255. 255. 255. 255. 255.\n",
            " 254. 255. 255. 255. 253. 255. 255.  13.   4.   0.   2.   3.  51. 237.\n",
            " 255. 251. 252. 255. 253. 255. 255. 255. 250. 255. 255. 252.  18.  46.\n",
            " 254. 255. 253. 253. 206.  46. 255. 255. 255. 255. 254. 253. 254. 255.\n",
            " 255. 250. 255.  19.  45. 255. 253. 255. 254. 253. 255.  15.  45. 255.\n",
            " 250. 255. 255. 255. 255. 254. 255. 252. 204.  49. 255. 253. 255. 254.\n",
            " 255. 254. 255. 255.   3. 254. 255. 255. 253. 252. 255. 252. 255. 255.\n",
            "  20. 237. 254. 255. 255. 249. 255. 255. 250. 254.   0. 254. 255. 251.\n",
            " 254. 255. 254. 255. 255. 252.   2. 255. 255. 253. 255. 255. 251. 255.\n",
            " 255. 255.   1. 255. 254. 255. 255. 255. 252. 255. 255. 255.   0. 255.\n",
            " 255. 255. 255. 253. 255. 255. 255. 255.   0. 255. 254. 254. 254. 254.\n",
            " 255. 251. 255. 255.   0. 255. 251. 255. 253. 255. 252. 253. 255. 252.\n",
            "   0. 255. 255. 253. 253. 254. 253. 255. 255. 253.   3. 253. 255. 252.\n",
            " 255. 255. 253. 255. 255. 255.   1. 255. 251. 255. 255. 255. 253. 252.\n",
            " 255. 251.   4. 255. 254. 255. 254. 254. 255. 250. 255. 255.   1. 254.\n",
            " 255. 253. 253. 255. 255. 253. 255. 255.   0. 255. 254. 255. 251. 255.\n",
            " 255. 255. 251. 255.   0. 254. 255. 255. 255. 255. 254. 250. 255. 255.\n",
            "   2. 254. 253. 255. 255. 252. 252. 254. 253.  15.  48. 255. 254. 252.\n",
            " 255. 254. 255. 255. 254. 255.  11. 241. 255. 252. 252.  35.   0.   2.\n",
            "   2.  46. 255. 255. 253. 255. 255. 255. 255. 253. 255. 253. 212.  45.\n",
            " 255. 255. 255. 254. 255.  60. 255. 255. 255. 253. 255. 254. 254. 255.\n",
            " 254. 255. 255. 254. 254.  17. 240. 254. 255. 255. 252.   3. 253. 254.\n",
            " 255. 255. 255. 255. 255. 250. 254. 255. 255. 253. 255. 204.  47. 253.\n",
            " 252. 255.  15.  45. 255. 255. 255. 255. 255. 255. 255. 255. 255. 253.\n",
            " 253. 255. 253. 255.  17.   0.   4.   0.  48. 253. 254. 253. 255. 255.\n",
            " 255. 255. 251. 255. 255. 254. 254. 255. 255. 251. 254. 255. 252. 254.\n",
            " 255. 254. 255. 255. 255. 255. 255. 255.]\n",
            "Epoch 1/15\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0000e+00 - accuracy: 0.5165\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7855e0d84be0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}