{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Putincew/python/blob/master/notebooks/%D0%B4%D0%B7_3_%D0%9B%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D1%8B%D0%B9_%D1%81%D0%BB%D0%BE%D0%B9_(Dense)_%7C_%D0%94%D0%97_Pro_%7C_%D0%A3%D0%98%D0%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_qXycKuUA51"
      },
      "source": [
        "### Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUMmCXubUHEb"
      },
      "source": [
        "Самостоятельно напишите нейронную сеть, которая может стать составной частью системы бота для игры в \"Крестики-нолики\". Используя подготовленную базу изображений, создайте и обучите нейронную сеть, распознающую две категории изображений: крестики и нолики. Добейтесь точности распознавания более 95% (accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvOL2h3EdC9y"
      },
      "source": [
        "# Подключение класса для создания нейронной сети прямого распространения\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Подключение класса для создания полносвязного слоя\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Подключение оптимизатора\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Подключение утилит для to_categorical\n",
        "from tensorflow.keras import utils\n",
        "# Подключение библиотеки для загрузки изображений\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# Подключение библиотеки для работы с массивами\n",
        "import numpy as np\n",
        "# Подключение модуля для работы с файлами\n",
        "import os\n",
        "# Подключение библиотек для отрисовки изображений\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Вывод изображения в ноутбуке, а не в консоли или файле\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lJSH41rM12IE",
        "outputId": "c12a421d-ac44-4a58-ede4-7fe9118aab8b"
      },
      "source": [
        "# Загрузка датасета из облака\n",
        "import gdown\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_pro.zip', None, quiet=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hw_pro.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HAhCsCJ1_hJ"
      },
      "source": [
        "# Распаковываем архив hw_light.zip в папку hw_light\n",
        "!unzip -q hw_pro.zip"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhHbCet01zmG",
        "outputId": "d2b2eee5-735e-410c-c1b6-b706a3ab5ab7"
      },
      "source": [
        "# Путь к директории с базой\n",
        "base_dir = '/content/hw_pro'\n",
        "# Создание пустого списка для загрузки изображений обучающей выборки\n",
        "x_train = []\n",
        "# Создание списка для меток классов\n",
        "y_train = []\n",
        "# Задание высоты и ширины загружаемых изображений\n",
        "img_height = 20\n",
        "img_width = 20\n",
        "# Перебор папок в директории базы\n",
        "for patch in os.listdir(base_dir):\n",
        "    # Перебор файлов в папках\n",
        "    for img in os.listdir(base_dir + '/' + patch):\n",
        "        # Добавление в список изображений текущей картинки\n",
        "        x_train.append(image.img_to_array(image.load_img(base_dir + '/' + patch + '/' + img,\n",
        "                                                         target_size=(img_height, img_width),\n",
        "                                                         color_mode='grayscale')))\n",
        "        # Добавление в массив меток, соответствующих классам\n",
        "        if patch == '0':\n",
        "            y_train.append(0)\n",
        "        else:\n",
        "            y_train.append(1)\n",
        "# Преобразование в numpy-массив загруженных изображений и меток классов\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "# Вывод размерностей\n",
        "print('Размер массива x_train', x_train.shape)\n",
        "print('Размер массива y_train', y_train.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер массива x_train (102, 20, 20, 1)\n",
            "Размер массива y_train (102,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJLh3F3N2DCD"
      },
      "source": [
        "x_tr, x_test, y_tr, y_test = train_test_split(x_train, y_train, test_size = 0.1, random_state = 43)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr = x_tr.reshape(x_tr.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "print(x_tr.shape)\n",
        "print(x_test.shape)\n",
        "model = Sequential()\n",
        "model.add(Dense(300, input_dim = 400, activation = \"relu\"))\n",
        "model.add(Dense(100, activation = \"relu\"))\n",
        "model.add(Dense(1, activation = \"softmax\"))\n",
        "\n",
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "\n",
        "model.fit(x_tr, y_tr, batch_size = 128, epochs = 15, verbose = 1, validation_split=0.2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQcRfwN_hjPs",
        "outputId": "365868c8-f3dd-4639-9bf9-22ea5bcb6a98"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(91, 400)\n",
            "(11, 400)\n",
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 2/15\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 3/15\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 4/15\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 5/15\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 6/15\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 7/15\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 8/15\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 9/15\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 10/15\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 11/15\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 12/15\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 13/15\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 14/15\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 15/15\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0000e+00 - accuracy: 0.5139 - val_loss: 0.0000e+00 - val_accuracy: 0.4737\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f6e3cd13820>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}